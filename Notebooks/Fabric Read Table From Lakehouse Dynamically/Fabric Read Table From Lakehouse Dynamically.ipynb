{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4d2c4a-7ac4-495b-afc3-729a40ff8542",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Notebook Fabric Read Table from Lakehouse Dynamically\n",
    "#### This code dynamically retrieves Fabric workspace and Lakehouse IDs, builds the OneLake path, and reads (or optionally writes) a Delta table using Spark.\n",
    "#### It is good practice to retrieve lakehouse ID and Workspace ID to make sure notebooks are ready for CI/CD and run across environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed22fcf-dcb9-43bc-9ded-204f2e5e9b02",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "#Get workspace and Lakehouse IDs dynamically \n",
    "workspace_id = spark.conf.get('trident.workspace.id') \n",
    "lakehouse_id = notebookutils.lakehouse.get(\"Bronze\", workspace_id).id # -> replace with workspace name\n",
    "schema_name= 'dbo' # -> replace with schema name\n",
    "table_name = 'Table1'# -> replace with table nam\n",
    "\n",
    "### Read data directly from OneLake \n",
    "path = f\"abfss://\"+workspace_id+\"@onelake.dfs.fabric.microsoft.com/\"+lakehouse_id+\"/Tables/\"+schema_name+\"/\"+table_name\n",
    "df = spark.read.format(\"delta\").load(path)\n",
    "###\n",
    "\n",
    "### #Write data directly to OneLake \n",
    "\n",
    "#df.write.format(\"delta\").mode(\"overwrite\").save(f\"abfss://\"+workspace_id+\"@onelake.dfs.fabric.microsoft.com/\"+lakehouse_id+\"/Tables/\"+schema_name+\"/\"+table_name\")\n",
    "\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

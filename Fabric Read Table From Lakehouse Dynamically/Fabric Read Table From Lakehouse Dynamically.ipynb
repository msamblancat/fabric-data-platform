{"cells":[{"cell_type":"markdown","source":["# Notebook Fabric Read Table from Lakehouse Dynamically\n","### This code dynamically retrieves Fabric workspace and Lakehouse IDs, builds the OneLake path, and reads (or optionally writes) a Delta table using Spark.\n","### It is good practice to retrieve lakehouse ID and Workspace ID to make sure notebooks are ready for CI/CD and run across environment. "],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1c4d2c4a-7ac4-495b-afc3-729a40ff8542"},{"cell_type":"code","source":["#Get workspace and Lakehouse IDs dynamically \n","workspace_id = spark.conf.get('trident.workspace.id') \n","lakehouse_id = notebookutils.lakehouse.get(\"Bronze\", workspace_id).id # -> replace with workspace name\n","schema_name= 'dbo' # -> replace with schema name\n","table_name = 'Table1'# -> replace with table nam\n","\n","### Read data directly from OneLake \n","path = f\"abfss://\"+workspace_id+\"@onelake.dfs.fabric.microsoft.com/\"+lakehouse_id+\"/Tables/\"+schema_name+\"/\"+table_name\n","df = spark.read.format(\"delta\").load(path)\n","###\n","\n","### #Write data directly to OneLake \n","\n","#df.write.format(\"delta\").mode(\"overwrite\").save(f\"abfss://\"+workspace_id+\"@onelake.dfs.fabric.microsoft.com/\"+lakehouse_id+\"/Tables/\"+schema_name+\"/\"+table_name\")\n","\n","###"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"023ad711-ad00-4563-9ca2-0367230f867f","normalized_state":"finished","queued_time":"2026-01-12T15:31:33.6335191Z","session_start_time":null,"execution_start_time":"2026-01-12T15:31:33.6345916Z","execution_finish_time":"2026-01-12T15:31:36.359095Z","parent_msg_id":"c6182fa4-5827-4e63-a696-d81f559882fa"},"text/plain":"StatementMeta(, 023ad711-ad00-4563-9ca2-0367230f867f, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2ed22fcf-dcb9-43bc-9ded-204f2e5e9b02"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}